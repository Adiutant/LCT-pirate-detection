{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ah11AbNx1Utd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
      "Requirement already satisfied: torchvision in /home/roman/.local/lib/python3.10/site-packages (0.17.1)\n",
      "Requirement already satisfied: opencv-python in /home/roman/.local/lib/python3.10/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: jinja2 in /home/roman/.local/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: fsspec in /home/roman/.local/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/roman/.local/lib/python3.10/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: numpy in /home/roman/.local/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/roman/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (9.0.1)\n",
      "Requirement already satisfied: scikit-learn in /home/roman/.local/lib/python3.10/site-packages (1.1.0)\n",
      "Collecting cupy\n",
      "  Downloading cupy-13.1.0.tar.gz (3.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /home/roman/.local/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/roman/.local/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/roman/.local/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/roman/.local/lib/python3.10/site-packages (from scikit-learn) (3.3.0)\n",
      "Collecting fastrlock>=0.5\n",
      "  Using cached fastrlock-0.8.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (51 kB)\n",
      "Building wheels for collected packages: cupy\n",
      "  Building wheel for cupy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cupy: filename=cupy-13.1.0-cp310-cp310-linux_x86_64.whl size=88744733 sha256=a41df0675493ba6c4a33171f7d9d88115a7d848a1442b3a74f92a0096f5b59fc\n",
      "  Stored in directory: /home/roman/.cache/pip/wheels/3c/f7/fd/f440432bc00ac2dd12e25ed1b47e30b3fb6744fb46eebcc066\n",
      "Successfully built cupy\n",
      "Installing collected packages: fastrlock, cupy\n",
      "Successfully installed cupy-13.1.0 fastrlock-0.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision opencv-python \n",
    "!pip install Pillow scikit-learn cupy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jJFqGwYm1Ye4"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "import zipfile\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "from scipy.signal import find_peaks, peak_widths\n",
    "from PIL import Image\n",
    "import gc\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nz4mgf9m1awe",
    "outputId": "3d1ec10d-e962-4fa7-9958-0169b1e1c782"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roman/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/roman/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet50(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Преобразования для входных данных модели\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "# Select the desired layer\n",
    "layer = model._modules.get('avgpool')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GGZnzHdz1hWZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_frame_embedding(frame, model, preprocess, device):\n",
    "    input_tensor = preprocess(frame).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        embedding = model(input_tensor)\n",
    "    return embedding\n",
    "\n",
    "def extract_frame_embeddings(video_path, model, preprocess, device, layer, frame_interval=None):\n",
    "    # Открытие видеофайла\n",
    "    outputs = []\n",
    "\n",
    "    # attach hook to the penultimate layer\n",
    "    def copy_embeddings(m, i, o):\n",
    "        \"\"\"Copy embeddings from the penultimate layer.\"\"\"\n",
    "        o = o[:, :, 0, 0].detach().cpu().squeeze().numpy().tolist()\n",
    "        outputs.append(o)\n",
    "\n",
    "    _ = layer.register_forward_hook(copy_embeddings)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    if frame_interval is None:\n",
    "        frame_interval = int(fps)\n",
    "    print(f\"Framerate is {frame_interval}\")\n",
    "\n",
    "    frames = []\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_interval == 0:\n",
    "            frames.append(frame)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Параллельная обработка кадров\n",
    "    for frame in frames:\n",
    "        _ = extract_frame_embedding(frame, model, preprocess, device)\n",
    "\n",
    "    return np.array(outputs)\n",
    "\n",
    "\n",
    "def extract_videos_from_zip(zip_path, filename, model, preprocess, device, layer ):\n",
    "    embeddings_dict = {}\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        video_files = [f for f in zip_ref.namelist() if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "        for video_file in video_files:\n",
    "            if filename not in video_file:\n",
    "                continue\n",
    "            print(f\"Processing {video_file}...\")\n",
    "\n",
    "            with zip_ref.open(video_file) as video_stream:\n",
    "\n",
    "                # Чтение видео из байтового потока\n",
    "                video_data = video_stream.read()\n",
    "                video_array = np.frombuffer(video_data, np.uint8)\n",
    "\n",
    "\n",
    "                # Временный файл для OpenCV VideoCapture\n",
    "                temp_video_path = 'temp_video.mp4'\n",
    "                with open(temp_video_path, 'wb') as temp_video_file:\n",
    "                    temp_video_file.write(video_data)\n",
    "\n",
    "                # Извлечение эмбеддингов из видео\n",
    "                embeddings = extract_frame_embeddings(temp_video_path, model, preprocess, device, layer)\n",
    "                #embeddings = extract_frame_embeddings_lib(temp_video_path)\n",
    "                embeddings_dict[video_file] = embeddings\n",
    "\n",
    "    return embeddings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JaQ80LDSpxVD"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/media/roman/Transcend/rutube/piracy_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "hYZ044xtr5bM",
    "outputId": "232c52f3-3ad1-40ee-c5ae-f9f426aefb75"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID_piracy</th>\n",
       "      <th>segment</th>\n",
       "      <th>ID_license</th>\n",
       "      <th>segment.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ydcrodwtz3mstjq1vhbdflx6kyhj3y0p.mp4</td>\n",
       "      <td>1539-1685</td>\n",
       "      <td>ded3d179001b3f679a0101be95405d2c.mp4</td>\n",
       "      <td>546-692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>t9j5gg42w6s7f62uybhtc51aj5nq9vxd.mp4</td>\n",
       "      <td>158-222</td>\n",
       "      <td>f4b1fd188fe77f9f56de07e867128b13.mp4</td>\n",
       "      <td>392-456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>zui6ud3solfndyetlralstpcjmv3br1f.mp4</td>\n",
       "      <td>139-263</td>\n",
       "      <td>aa16953bbb8fdb2dfc5fc368f4abe89a.mp4</td>\n",
       "      <td>656-780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>aozskym3m7s9ibw5xpgca7m5jqe240vs.mp4</td>\n",
       "      <td>306-449</td>\n",
       "      <td>3219f476e4bc29f6f420e4e6b05ae8bb.mp4</td>\n",
       "      <td>399-542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3y78kqwdr5lbtsy9tb76n5ylbcrainsx.mp4</td>\n",
       "      <td>517-590</td>\n",
       "      <td>cb718f23524eb08af2f8036eedc6b50c.mp4</td>\n",
       "      <td>119-192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>133</td>\n",
       "      <td>4ojku252jnbtv04wtnvm73x08xyftpgy.mp4</td>\n",
       "      <td>466-632</td>\n",
       "      <td>fd316c0e150c30ba2156f82e65bfea62.mp4</td>\n",
       "      <td>322-488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>134</td>\n",
       "      <td>iflvtrjcx50j1kgbb3zgbvpql6zm2gry.mp4</td>\n",
       "      <td>196-471</td>\n",
       "      <td>a808f0de343faf6320bcc94ea57c5381.mp4</td>\n",
       "      <td>462-737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>135</td>\n",
       "      <td>ztbk9ua8hx1u6l3ol3q5ehh8ugxqlrpd.mp4</td>\n",
       "      <td>165-213</td>\n",
       "      <td>ce9697edebdbec509944e8a010d91d0e.mp4</td>\n",
       "      <td>59-107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>136</td>\n",
       "      <td>dtpq232karpm09ldxucjqip32hfblrkz.mp4</td>\n",
       "      <td>98-231</td>\n",
       "      <td>8cc8785efca469cdb6fb6efdcd3421d2.mp4</td>\n",
       "      <td>227-360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>137</td>\n",
       "      <td>si2m5i2ne4b8oih1mjcyo2lg62ujh3si.mp4</td>\n",
       "      <td>164-233</td>\n",
       "      <td>d515a3eb5f4de4ae0e14ddefa98ef06f.mp4</td>\n",
       "      <td>296-365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                             ID_piracy    segment  \\\n",
       "0             0  ydcrodwtz3mstjq1vhbdflx6kyhj3y0p.mp4  1539-1685   \n",
       "1             1  t9j5gg42w6s7f62uybhtc51aj5nq9vxd.mp4    158-222   \n",
       "2             2  zui6ud3solfndyetlralstpcjmv3br1f.mp4    139-263   \n",
       "3             3  aozskym3m7s9ibw5xpgca7m5jqe240vs.mp4    306-449   \n",
       "4             4  3y78kqwdr5lbtsy9tb76n5ylbcrainsx.mp4    517-590   \n",
       "..          ...                                   ...        ...   \n",
       "133         133  4ojku252jnbtv04wtnvm73x08xyftpgy.mp4    466-632   \n",
       "134         134  iflvtrjcx50j1kgbb3zgbvpql6zm2gry.mp4    196-471   \n",
       "135         135  ztbk9ua8hx1u6l3ol3q5ehh8ugxqlrpd.mp4    165-213   \n",
       "136         136  dtpq232karpm09ldxucjqip32hfblrkz.mp4     98-231   \n",
       "137         137  si2m5i2ne4b8oih1mjcyo2lg62ujh3si.mp4    164-233   \n",
       "\n",
       "                               ID_license segment.1  \n",
       "0    ded3d179001b3f679a0101be95405d2c.mp4   546-692  \n",
       "1    f4b1fd188fe77f9f56de07e867128b13.mp4   392-456  \n",
       "2    aa16953bbb8fdb2dfc5fc368f4abe89a.mp4   656-780  \n",
       "3    3219f476e4bc29f6f420e4e6b05ae8bb.mp4   399-542  \n",
       "4    cb718f23524eb08af2f8036eedc6b50c.mp4   119-192  \n",
       "..                                    ...       ...  \n",
       "133  fd316c0e150c30ba2156f82e65bfea62.mp4   322-488  \n",
       "134  a808f0de343faf6320bcc94ea57c5381.mp4   462-737  \n",
       "135  ce9697edebdbec509944e8a010d91d0e.mp4    59-107  \n",
       "136  8cc8785efca469cdb6fb6efdcd3421d2.mp4   227-360  \n",
       "137  d515a3eb5f4de4ae0e14ddefa98ef06f.mp4   296-365  \n",
       "\n",
       "[138 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "AMYMEHixqMQ3"
   },
   "outputs": [],
   "source": [
    "row_test = 79\n",
    "def get_piracy_lic_embeddings(piracy_id, license_id):\n",
    "\n",
    "    zip_path = '/media/roman/Transcend/rutube/index.zip'\n",
    "    embeddings_dict_license = extract_videos_from_zip(zip_path, license_id, model, preprocess, device, layer)\n",
    "    zip_path = '/media/roman/Transcend/rutube/val.zip'\n",
    "    embeddings_dict_piracy = extract_videos_from_zip(zip_path, piracy_id, model, preprocess, device, layer)\n",
    "    embeddings_dict = dict(list(embeddings_dict_license.items()) + list(embeddings_dict_piracy.items()))\n",
    "    license_np = np.asarray(list(embeddings_dict.values())[0], dtype=\"float64\")\n",
    "    piracy_np = np.asarray(list(embeddings_dict.values())[1], dtype=\"float64\")\n",
    "    return  piracy_np,license_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "A-L4WR8pwzyu"
   },
   "outputs": [],
   "source": [
    "def cosine_distance_gpu(A, B):\n",
    "    # Убедимся, что входные данные являются cupy массивами\n",
    "    if not isinstance(A, cp.ndarray):\n",
    "\n",
    "        A = cp.array(A)\n",
    "    if not isinstance(B, cp.ndarray):\n",
    "        B = cp.array(B)\n",
    "    \n",
    "    dot_product = cp.dot(A, B.T)\n",
    "    norm_A = cp.linalg.norm(A, axis=1, keepdims=True)\n",
    "    norm_B = cp.linalg.norm(B, axis=1, keepdims=True)\n",
    "    return 1 - dot_product / (norm_A * norm_B.T)\n",
    "\n",
    "def gpu_cosine_distance_matrix(matrix1, matrix2):\n",
    "    # Убедимся, что входные данные являются cupy массивами\n",
    "    if not isinstance(matrix1, cp.ndarray):\n",
    "        matrix1 = cp.array(matrix1)\n",
    "    if not isinstance(matrix2, cp.ndarray):\n",
    "        matrix2 = cp.array(matrix2)\n",
    "    \n",
    "    # Вычисляем косинусное расстояние между всеми парами строк матриц\n",
    "    distance_matrix = cosine_distance_gpu(matrix1, matrix2)\n",
    "    # Преобразуем cupy array в numpy array\n",
    "    distance_matrix = distance_matrix.get()\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3AIMlaLzykEK",
    "outputId": "2902d856-e30d-4272-b2ee-cabccb679528"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair of license afa4ac13ec1628e7f66493783cf7550e.mp4 and pirate wd6i4pislndwtth1hc0yrg23f9y3r8gw.mp4 has interval 53-134 and 642-723\n",
      "Processing compressed_index/afa4ac13ec1628e7f66493783cf7550e.mp4...\n",
      "Framerate is 10\n",
      "Processing compressed_val/wd6i4pislndwtth1hc0yrg23f9y3r8gw.mp4...\n",
      "Framerate is 10\n"
     ]
    }
   ],
   "source": [
    "piracy =  df.iloc[row_test][\"ID_piracy\"]\n",
    "license = df.iloc[row_test][\"ID_license\"]\n",
    "segment_piracy = df.iloc[row_test][\"segment\"]\n",
    "segment_lic = df.iloc[row_test][\"segment.1\"]\n",
    "print (f\"Pair of license {license} and pirate {piracy} has interval {segment_piracy} and {segment_lic}\")\n",
    "piracy_np, license_np = get_piracy_lic_embeddings(piracy, license)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0NRtGOa8zsHE",
    "outputId": "43511f37-7ad4-4bb8-f52d-0c8821fcaaf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1441, 2048)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "license_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jemKs7nyva8Q",
    "outputId": "8b8c5c8b-2304-41f7-c7a3-7519ff9a4c80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379, 2048)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piracy_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ItUfg0_D3V2U",
    "outputId": "3df33b7e-8278-424a-bb40-84eae6f58919"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(license_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "sh-tYnb6x9O5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roman/.local/lib/python3.10/site-packages/cupy/cuda/compiler.py:233: PerformanceWarning: Jitify is performing a one-time only warm-up to populate the persistent cache, this may take a few seconds and will be improved in a future release...\n",
      "  jitify._init_module()\n"
     ]
    }
   ],
   "source": [
    "matrix = gpu_cosine_distance_matrix(piracy_np, license_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "F_sRzvLQHU-d"
   },
   "outputs": [],
   "source": [
    "def make_plt_rows(matrix_l):\n",
    "    points_dict = {}\n",
    "\n",
    "    # Проходимся по строкам матрицы косинусных расстояний\n",
    "    for i in range(max(matrix_l.shape[0], matrix_l.shape[1])):\n",
    "        points_dict[i] = 0\n",
    "    max_value_global = np.max(np.abs(matrix_l))\n",
    "    mean_value_global = np.mean(np.abs(matrix_l))\n",
    "    for i in range(matrix_l.shape[0]):\n",
    "        min_index = np.argmin(matrix_l[i])\n",
    "        min_value = matrix_l[i, min_index]\n",
    "\n",
    "\n",
    "        # Вычисляем y-координату для точки на графике\n",
    "        y_value = max_value_global - min_value\n",
    "\n",
    "        if (min_value < mean_value_global):\n",
    "            points_dict[min_index] =y_value\n",
    "\n",
    "    # Преобразуем словарь в списки для построения графика\n",
    "    x_points = list(points_dict.keys())\n",
    "    y_points = list(points_dict.values())\n",
    "    # Убедимся, что все значения y положительны\n",
    "    y_points = np.maximum(y_points, 0)\n",
    "\n",
    "    sorted_indices = np.argsort(x_points)\n",
    "    print(max(x_points))\n",
    "    x_points = np.take(np.array(x_points),sorted_indices)\n",
    "    y_points = np.take(np.array(y_points),sorted_indices)\n",
    "    print(max(x_points))\n",
    "    def moving_average(data, window_size):\n",
    "        return np.convolve(data, np.ones(window_size)/window_size, mode='same')\n",
    "\n",
    "    window_size = max(int(y_points.shape[0] * 0.05), 3)\n",
    "    y_points_smoothed = moving_average(y_points, window_size)\n",
    "\n",
    "    f_interp = PchipInterpolator(x_points, y_points_smoothed)\n",
    "    x_smooth = np.linspace(x_points.min(), x_points.max(), len(x_points))\n",
    "    y_smooth = f_interp(x_smooth)\n",
    "\n",
    "    peaks, _ = find_peaks(y_smooth)\n",
    "    widths_half_max = peak_widths(y_smooth, peaks, rel_height=0.50)\n",
    "\n",
    "    max_peak_idx = np.argmax(y_smooth[peaks])\n",
    "    max_peak_height = y_smooth[peaks][max_peak_idx]\n",
    "\n",
    "    max_width_idx = np.argmax(widths_half_max[0])\n",
    "    max_peak_width = widths_half_max[0][max_width_idx]\n",
    "    left_ips_x = 0\n",
    "    right_ips_x = 0\n",
    "    if peaks[max_peak_idx] == peaks[max_width_idx]:\n",
    "        print(f\"Пик одновременно самый высокий и самый широкий: высота={max_peak_height}, ширина={max_peak_width}\")\n",
    "\n",
    "        left_ips_x = x_smooth[int(widths_half_max[2][max_width_idx])]\n",
    "        right_ips_x = x_smooth[int(widths_half_max[3][max_width_idx])]\n",
    "\n",
    "        print(f\"Границы пика относительно оси x: {left_ips_x}, {right_ips_x}\")\n",
    "    elif peaks[max_peak_idx]: #and widths_half_max[0][max_peak_idx] > 50:\n",
    "        left_ips_x = x_smooth[int(widths_half_max[2][max_peak_idx])]\n",
    "        right_ips_x = x_smooth[int(widths_half_max[3][max_peak_idx])]\n",
    "\n",
    "        print(f\"Границы пика относительно оси x: {left_ips_x}, {right_ips_x}\")\n",
    "    # plt.plot(x_smooth, y_smooth)\n",
    "    # plt.xlabel('Index of Minimum Cosine Distance')\n",
    "    # plt.ylabel('Sum of Max Value - Min Value')\n",
    "    # plt.title('Graph of Minimum Cosine Distances with Peaks')\n",
    "    # plt.grid(True)\n",
    "    # plt.show()\n",
    "    return f\"{left_ips_x}-{right_ips_x}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PhStJyYocBZB"
   },
   "outputs": [],
   "source": [
    "def make_plt_columns(matrix_l):\n",
    "    points_dict = {}\n",
    "    for j in range(max(matrix_l.shape[0], matrix_l.shape[1])):\n",
    "        points_dict[j] = 0\n",
    "    print(matrix_l.shape[1])\n",
    "    max_value_global = np.max(np.abs(matrix_l))\n",
    "    mean_value_global = np.mean(np.abs(matrix_l))\n",
    "    # Проходимся по строкам матрицы косинусных расстояний\n",
    "    for j in range(matrix_l.shape[1]):\n",
    "        min_index = np.argmin(matrix_l[:, j])\n",
    "        min_value = matrix_l[min_index, j]\n",
    "\n",
    "        # Вычисляем y-координату для точки на графике\n",
    "        y_value = max_value_global - min_value\n",
    "\n",
    "        if (min_value < mean_value_global):\n",
    "            points_dict[min_index] =y_value\n",
    "\n",
    "    x_points = list(points_dict.keys())\n",
    "    y_points = list(points_dict.values())\n",
    "\n",
    "\n",
    "    sorted_indices = np.argsort(x_points)\n",
    "    print(max(x_points))\n",
    "    x_points = np.take(np.array(x_points),sorted_indices)\n",
    "    y_points = np.take(np.array(y_points),sorted_indices)\n",
    "    print(max(x_points))\n",
    "    def moving_average(data, window_size):\n",
    "        return np.convolve(data, np.ones(window_size)/window_size, mode='same')\n",
    "\n",
    "    window_size = max(int(y_points.shape[0] * 0.05), 3)\n",
    "    y_points_smoothed = moving_average(y_points, window_size)\n",
    "\n",
    "    f_interp = PchipInterpolator(x_points, y_points_smoothed)\n",
    "    x_smooth = np.linspace(x_points.min(), x_points.max(), len(x_points))\n",
    "    y_smooth = f_interp(x_smooth)\n",
    "\n",
    "    peaks, _ = find_peaks(y_smooth)\n",
    "    widths_half_max = peak_widths(y_smooth, peaks, rel_height=0.50)\n",
    "\n",
    "    max_peak_idx = np.argmax(y_smooth[peaks])\n",
    "    max_peak_height = y_smooth[peaks][max_peak_idx]\n",
    "\n",
    "    max_width_idx = np.argmax(widths_half_max[0])\n",
    "    max_peak_width = widths_half_max[0][max_width_idx]\n",
    "    left_ips_x = 0\n",
    "    right_ips_x = 0\n",
    "    if peaks[max_peak_idx] == peaks[max_width_idx]:\n",
    "        print(f\"Пик одновременно самый высокий и самый широкий: высота={max_peak_height}, ширина={max_peak_width}\")\n",
    "\n",
    "        left_ips_x = x_smooth[int(widths_half_max[2][max_width_idx])]\n",
    "        right_ips_x = x_smooth[int(widths_half_max[3][max_width_idx])]\n",
    "\n",
    "        print(f\"Границы пика относительно оси x: {left_ips_x}, {right_ips_x}\")\n",
    "    elif peaks[max_peak_idx]: #and widths_half_max[0][max_peak_idx] > 50#:\n",
    "        left_ips_x = x_smooth[int(widths_half_max[2][max_peak_idx])]\n",
    "        right_ips_x = x_smooth[int(widths_half_max[3][max_peak_idx])]\n",
    "\n",
    "        print(f\"Границы пика относительно оси x: {left_ips_x}, {right_ips_x}\")\n",
    "\n",
    "    # plt.plot(x_smooth, y_smooth)\n",
    "    # plt.xlabel('Index of Minimum Cosine Distance')\n",
    "    # plt.ylabel('Sum of Max Value - Min Value')\n",
    "    # plt.title('Graph of Minimum Cosine Distances with Peaks')\n",
    "    # plt.grid(True)\n",
    "    # plt.show()\n",
    "    return f\"{left_ips_x}-{right_ips_x}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ishZqx540ATa",
    "outputId": "c1fe69f7-1033-4f16-9a53-e383529ef95b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 1441)\n"
     ]
    }
   ],
   "source": [
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "alc1xaWp21m4",
    "outputId": "369dc148-66c0-4969-8394-b513fe25cc1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(matrix[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "id": "cL4VkK8q0Rox",
    "outputId": "17e3b3db-9936-41c6-8797-04db145fef82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440\n",
      "1440\n",
      "Границы пика относительно оси x: 644.0, 725.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'644.0-725.0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "make_plt_rows(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "sAe3LilQBp4g",
    "outputId": "855d81b5-a619-40d6-e1f9-ef10b15b8d53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1441\n",
      "1440\n",
      "1440\n",
      "Границы пика относительно оси x: 49.0, 130.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44336/3498212911.py:39: PeakPropertyWarning: some peaks have a width of 0\n",
      "  widths_half_max = peak_widths(y_smooth, peaks, rel_height=0.50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'49.0-130.0'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_plt_columns(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "2_E6HZ6cx3pt"
   },
   "outputs": [],
   "source": [
    "def get_intervals(id_piracy, id_license):\n",
    "    piracy_l ,license_l= get_piracy_lic_embeddings(id_piracy, id_license)\n",
    "    matrix_l = gpu_cosine_distance_matrix(license_l, piracy_l)\n",
    "    result = make_plt_rows(matrix_l), make_plt_columns(matrix_l)\n",
    "    del matrix_l\n",
    "    del license_l\n",
    "    del piracy_l\n",
    "    gc.collect()\n",
    "    return result\n",
    "\n",
    "\n",
    "def parse_segment(segment):\n",
    "    start, end = map(float, segment.split(\"-\"))\n",
    "    return start, end\n",
    "\n",
    "\n",
    "def iou(segment_q, segment_t):\n",
    "    start_q, stop_q = parse_segment(segment_q)\n",
    "    start_t, stop_t = parse_segment(segment_t)\n",
    "\n",
    "    intersection_start = max(start_q, start_t)\n",
    "    intersection_end = min(stop_q, stop_t)\n",
    "\n",
    "    intersection_length = max(0, intersection_end - intersection_start)\n",
    "    union_length = (stop_q - start_q) + (stop_t - start_t) - intersection_length\n",
    "\n",
    "    iou = intersection_length / union_length if union_length > 0 else 0\n",
    "    return iou\n",
    "\n",
    "\n",
    "\n",
    "# Вычисляем метрики IOU и их произведение без добавления промежуточных колонок\n",
    "def calculate_iou_product(row):\n",
    "    piracy_l =  row[\"ID_piracy\"]\n",
    "    license_l = row[\"ID_license\"]\n",
    "    segment_piracy_l = row[\"segment\"]\n",
    "    segment_lic_l = row[\"segment.1\"]\n",
    "    print(f\"Pair of priracy {piracy_l} and license {license_l} has interval {segment_piracy_l} and {segment_lic_l}\")\n",
    "    interval_piracy, interval_license = get_intervals(piracy_l, license_l)\n",
    "    iou_piracy = iou(segment_piracy_l, interval_piracy)\n",
    "    iou_license = iou(segment_lic_l, interval_license)\n",
    "    print(f\"{interval_piracy} | {interval_license} IOU p {iou_piracy} IOU l {iou_license}\")\n",
    "    return iou_piracy * iou_license\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 533
    },
    "id": "-iTvinjV1FlY",
    "outputId": "271ab881-0b90-4b4d-d13a-c0c0e779e67e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair of priracy ydcrodwtz3mstjq1vhbdflx6kyhj3y0p.mp4 and license ded3d179001b3f679a0101be95405d2c.mp4 has interval 1539-1685 and 546-692\n",
      "Processing compressed_index/ded3d179001b3f679a0101be95405d2c.mp4...\n",
      "Framerate is 10\n",
      "Processing compressed_val/ydcrodwtz3mstjq1vhbdflx6kyhj3y0p.mp4...\n",
      "Framerate is 10\n",
      "1777\n",
      "1777\n",
      "Границы пика относительно оси x: 1521.0, 1677.0\n",
      "1778\n",
      "1777\n",
      "1777\n",
      "Пик одновременно самый высокий и самый широкий: высота=0.26046930988092226, ширина=136.28469328817891\n",
      "Границы пика относительно оси x: 1167.0, 1303.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44336/464454489.py:42: PeakPropertyWarning: some peaks have a width of 0\n",
      "  widths_half_max = peak_widths(y_smooth, peaks, rel_height=0.50)\n",
      "/tmp/ipykernel_44336/3498212911.py:39: PeakPropertyWarning: some peaks have a width of 0\n",
      "  widths_half_max = peak_widths(y_smooth, peaks, rel_height=0.50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1521.0-1677.0 | 1167.0-1303.0 IOU p 0.8414634146341463 IOU l 0.0\n",
      "Pair of priracy t9j5gg42w6s7f62uybhtc51aj5nq9vxd.mp4 and license f4b1fd188fe77f9f56de07e867128b13.mp4 has interval 158-222 and 392-456\n",
      "Processing compressed_index/f4b1fd188fe77f9f56de07e867128b13.mp4...\n",
      "Framerate is 10\n",
      "Processing compressed_val/t9j5gg42w6s7f62uybhtc51aj5nq9vxd.mp4...\n",
      "Framerate is 10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miou_product\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalculate_iou_product\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:10361\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10347\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10349\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10350\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10351\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10359\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10360\u001b[0m )\n\u001b[0;32m> 10361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[20], line 39\u001b[0m, in \u001b[0;36mcalculate_iou_product\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     37\u001b[0m segment_lic_l \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegment.1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPair of priracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpiracy_l\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and license \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlicense_l\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has interval \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msegment_piracy_l\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msegment_lic_l\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m interval_piracy, interval_license \u001b[38;5;241m=\u001b[39m \u001b[43mget_intervals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpiracy_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlicense_l\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m iou_piracy \u001b[38;5;241m=\u001b[39m iou(segment_piracy_l, interval_piracy)\n\u001b[1;32m     41\u001b[0m iou_license \u001b[38;5;241m=\u001b[39m iou(segment_lic_l, interval_license)\n",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m, in \u001b[0;36mget_intervals\u001b[0;34m(id_piracy, id_license)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_intervals\u001b[39m(id_piracy, id_license):\n\u001b[1;32m      2\u001b[0m     piracy_l ,license_l\u001b[38;5;241m=\u001b[39m get_piracy_lic_embeddings(id_piracy, id_license)\n\u001b[0;32m----> 3\u001b[0m     matrix_l \u001b[38;5;241m=\u001b[39m \u001b[43mgpu_cosine_distance_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlicense_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpiracy_l\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     result \u001b[38;5;241m=\u001b[39m make_plt_rows(matrix_l), make_plt_columns(matrix_l)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m matrix_l\n",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m, in \u001b[0;36mgpu_cosine_distance_matrix\u001b[0;34m(matrix1, matrix2)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(rows_matrix1):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(rows_matrix2):\n\u001b[0;32m---> 16\u001b[0m         distance_matrix[i, j] \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_distance_gpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Преобразуем cupy array в numpy array\u001b[39;00m\n\u001b[1;32m     18\u001b[0m distance_matrix \u001b[38;5;241m=\u001b[39m distance_matrix\u001b[38;5;241m.\u001b[39mget()\n",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m, in \u001b[0;36mcosine_distance_gpu\u001b[0;34m(A, B)\u001b[0m\n\u001b[1;32m      4\u001b[0m dot_product \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mdot(A, B)\n\u001b[1;32m      5\u001b[0m norm_A \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(A)\n\u001b[0;32m----> 6\u001b[0m norm_B \u001b[38;5;241m=\u001b[39m \u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m dot_product \u001b[38;5;241m/\u001b[39m (norm_A \u001b[38;5;241m*\u001b[39m norm_B)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/cupy/linalg/_norms.py:62\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m     60\u001b[0m     ret \u001b[38;5;241m=\u001b[39m cupy\u001b[38;5;241m.\u001b[39msqrt(s\u001b[38;5;241m.\u001b[39msum())\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcupy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keepdims:\n\u001b[1;32m     64\u001b[0m     ret \u001b[38;5;241m=\u001b[39m ret\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m*\u001b[39m ndim)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df['iou_product'] = df.apply(calculate_iou_product, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q92rZz8wHASS",
    "outputId": "c58067ea-f0a5-4a24-949c-30026408051d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00013616403823634208\n",
      "[[0 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]]\n",
      "[array([4, 5, 6]), array([7, 8, 9])]\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "\n",
    "def cosine_distance_gpu(A, B):\n",
    "    dot_product = cp.dot(A, B)\n",
    "    norm_A = cp.linalg.norm(A)\n",
    "    norm_B = cp.linalg.norm(B)\n",
    "    return 1 - dot_product / (norm_A * norm_B)\n",
    "\n",
    "def gpu_cosine_distance_matrix(matrix1, matrix2):\n",
    "    rows_matrix1 = matrix1.shape[0]\n",
    "    rows_matrix2 = matrix2.shape[0]\n",
    "    # Создаем матрицу для хранения косинусных расстояний на GPU\n",
    "    distance_matrix = cp.zeros((rows_matrix1, rows_matrix2))\n",
    "    for i in range(rows_matrix1):\n",
    "        for j in range(rows_matrix2):\n",
    "            distance_matrix[i, j] = cosine_distance_gpu(matrix1[i], matrix2[j])\n",
    "    # Преобразуем cupy array в numpy array\n",
    "    distance_matrix = distance_matrix.get()\n",
    "    return distance_matrix\n",
    "\n",
    "def lcs_from_cosine_distance(matrix1, matrix2):\n",
    "    # Вычисляем матрицу косинусных расстояний\n",
    "    distance_matrix = gpu_cosine_distance_matrix(matrix1, matrix2)\n",
    "\n",
    "    # Вычисляем среднее значение косинусного расстояния\n",
    "    mean_distance = cp.mean(distance_matrix)\n",
    "\n",
    "    # Устанавливаем порог как 25% от среднего значения\n",
    "    threshold = mean_distance * 0.01\n",
    "    print(threshold)\n",
    "    # Преобразуем матрицу расстояний в матрицу совпадений\n",
    "    match_matrix = (distance_matrix < threshold).astype(int)\n",
    "    print(match_matrix)\n",
    "    # Инициализируем DP таблицу\n",
    "    rows, cols = match_matrix.shape\n",
    "    dp = [[0] * (cols + 1) for _ in range(rows + 1)]\n",
    "\n",
    "    # Заполняем DP таблицу\n",
    "    for i in range(1, rows + 1):\n",
    "        for j in range(1, cols + 1):\n",
    "            if match_matrix[i-1][j-1] == 1:\n",
    "                dp[i][j] = dp[i-1][j-1] + 1\n",
    "            else:\n",
    "                dp[i][j] = max(dp[i-1][j], dp[i][j-1])\n",
    "\n",
    "    # Восстанавливаем LCS\n",
    "    lcs = []\n",
    "    i, j = rows, cols\n",
    "    while i > 0 and j > 0:\n",
    "        if match_matrix[i-1][j-1] == 1:\n",
    "            lcs.append(matrix1[i-1])\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif dp[i-1][j] > dp[i][j-1]:\n",
    "            i -= 1\n",
    "        else:\n",
    "            j -= 1\n",
    "\n",
    "    lcs.reverse()\n",
    "    return lcs\n",
    "\n",
    "# Пример использования:\n",
    "if __name__ == \"__main__\":\n",
    "    import numpy as np\n",
    "\n",
    "    # Пример данных\n",
    "    matrix1 = cp.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "    matrix2 = cp.array([ [4, 5, 6],[7, 8, 9], [10, 11, 12]])\n",
    "\n",
    "    result = lcs_from_cosine_distance(matrix1, matrix2)\n",
    "\n",
    "    # Преобразуем результат из cupy array в numpy array для вывода\n",
    "    result_np = [cp.asnumpy(arr) for arr in result]\n",
    "\n",
    "    print(result_np)  # Ожидается список numpy array с элементами LCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cNZ2ev7_GQ9i"
   },
   "outputs": [],
   "source": [
    "license_test = extract_frame_embeddings(\"lic.mp4\")\n",
    "piracy_test = extract_frame_embeddings(\"piracy.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31mQBLiRHD1C"
   },
   "outputs": [],
   "source": [
    "license_np_test = np.asarray(license_test, dtype=\"object\")\n",
    "piracy_np_test = np.asarray(piracy_test, dtype=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wYBjozEYHI6P"
   },
   "outputs": [],
   "source": [
    "print(piracy_np_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9RS66aUcHPgn"
   },
   "outputs": [],
   "source": [
    "matrix_test = cosine_distance_matrix(license_np_test, piracy_np_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cJg9lGc1HSUB"
   },
   "outputs": [],
   "source": [
    "print(matrix_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PlhgA270KP60"
   },
   "outputs": [],
   "source": [
    "make_plt_rows(matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OqXrbQR2KMJP"
   },
   "outputs": [],
   "source": [
    "make_plt_columns(matrix_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
