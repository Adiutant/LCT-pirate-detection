{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 8698528,
     "sourceType": "datasetVersion",
     "datasetId": 5212842
    }
   ],
   "dockerImageVersionId": 30733,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "def extract_frames(path, video_filename):\n    \n    # Используем OpenCV для чтения видео\n    cap = cv2.VideoCapture(path + video_filename)\n\n    # Получаем исходную частоту кадров видео\n    original_fps = cap.get(cv2.CAP_PROP_FPS)\n\n    frames = []\n    frame_count = 0\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Преобразуем кадр из BGR (OpenCV формат) в RGB\n        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\n        # Изменяем размер кадра до 224x224 (или другого размера по вашему выбору)\n\n        frame = cv2.resize(frame, (400, 400))\n    \n        # Проверяем, нужно ли сохранить текущий кадр\n        if frame_count % int(original_fps ) == 0:\n            frames.append(frame)  # Преобразуем в тензор и меняем порядок осей\n\n        frame_count += 1\n\n    cap.release()\n\n    return np.stack(frames, axis=0)",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2024-06-15T13:56:22.457795Z",
     "iopub.execute_input": "2024-06-15T13:56:22.458149Z",
     "iopub.status.idle": "2024-06-15T13:56:22.466071Z",
     "shell.execute_reply.started": "2024-06-15T13:56:22.458121Z",
     "shell.execute_reply": "2024-06-15T13:56:22.465060Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-15T17:13:42.269325Z",
     "start_time": "2024-06-15T17:13:42.263305Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": "def create_embedding_dataframe(video1_embeddings, video2_embeddings, interval1, interval2):\n    start1, end1 = map(int, interval1.split('-'))\n    start2, end2 = map(int, interval2.split('-'))\n\n    if (end1 - start1) != (end2 - start2):\n        raise ValueError(\"Интервалы должны быть одинаковой длины\")\n\n    frames1 = []\n    frames2 = []\n    is_match = []\n\n    # Добавляем совпадающие пары из интервалов\n    for i in range(end1 - start1):\n        emb1 = video1_embeddings[start1 + i]\n        emb2 = video2_embeddings[start2 + i]\n        \n        frames1.append(emb1)\n        frames2.append(emb2)\n        \n        is_match.append(1)\n\n    total_pairs = end1 - start1 + 1\n    all_indices_video1 = set(range(len(video1_embeddings)))\n    all_indices_video2 = set(range(len(video2_embeddings)))\n    interval_indices_video1 = set(range(start1, end1 + 1))\n    interval_indices_video2 = set(range(start2, end2 + 1))\n\n    non_interval_indices_video1 = list(all_indices_video1 - interval_indices_video1)\n    non_interval_indices_video2 = list(all_indices_video2 - interval_indices_video2)\n\n    if len(non_interval_indices_video1) < total_pairs or len(non_interval_indices_video2) < total_pairs:\n        raise ValueError(\"Недостаточно элементов вне интервала для создания случайных пар\")\n\n    random_pairs_added = 0\n    while random_pairs_added < total_pairs:\n        idx1 = np.random.choice(non_interval_indices_video1)\n        idx2 = np.random.choice(non_interval_indices_video2)\n\n        emb1 = video1_embeddings[idx1]\n        emb2 = video2_embeddings[idx2]\n\n        frames1.append(emb1)\n        frames2.append(emb2)\n        \n        is_match.append(0)\n\n        random_pairs_added += 1\n\n    df = pd.DataFrame({\n        'frames1': frames1,\n        'frames2' : frames2,\n        'is_match': is_match\n    })\n\n    df = df.sample(frac=1).reset_index(drop=True)\n\n    return df",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-15T14:06:39.120732Z",
     "iopub.execute_input": "2024-06-15T14:06:39.121745Z",
     "iopub.status.idle": "2024-06-15T14:06:39.133025Z",
     "shell.execute_reply.started": "2024-06-15T14:06:39.121703Z",
     "shell.execute_reply": "2024-06-15T14:06:39.132101Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-15T17:13:44.037140Z",
     "start_time": "2024-06-15T17:13:44.031763Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.DataFrame()\n",
    "df = pd.read_csv(\"piracy_val.csv\")\n",
    "for _,row in df.iterrows():\n",
    "    piracy_ = extract_frames('val/', row[\"ID_piracy\"])\n",
    "    license_ = extract_frames('index/', row[\"ID_license\"])\n",
    "    proxy_df = create_embedding_dataframe(piracy_, license_, row[\"segment\"], row[\"segment.1\"])\n",
    "    train_df = pd.concat([train_df, proxy_df], ignore_index=True)\n",
    "\n",
    "train_df.head(5)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-15T14:06:42.216104Z",
     "iopub.execute_input": "2024-06-15T14:06:42.216451Z",
     "iopub.status.idle": "2024-06-15T14:16:07.762074Z",
     "shell.execute_reply.started": "2024-06-15T14:06:42.216422Z",
     "shell.execute_reply": "2024-06-15T14:16:07.761049Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-15T17:15:35.547497Z",
     "start_time": "2024-06-15T17:13:45.016137Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                             frames1  \\\n",
       "0  [[[193, 149, 148], [193, 149, 148], [195, 151,...   \n",
       "1  [[[142, 137, 134], [145, 140, 137], [147, 142,...   \n",
       "2  [[[147, 155, 160], [147, 155, 160], [147, 155,...   \n",
       "3  [[[188, 194, 195], [188, 194, 195], [188, 194,...   \n",
       "4  [[[155, 174, 184], [156, 175, 185], [156, 175,...   \n",
       "\n",
       "                                             frames2  is_match  \n",
       "0  [[[57, 141, 56], [49, 133, 48], [61, 145, 60],...         0  \n",
       "1  [[[24, 22, 30], [24, 22, 30], [24, 22, 30], [2...         1  \n",
       "2  [[[33, 37, 41], [33, 37, 41], [33, 37, 41], [3...         1  \n",
       "3  [[[92, 11, 16], [92, 11, 16], [92, 11, 16], [9...         0  \n",
       "4  [[[217, 220, 227], [216, 219, 226], [215, 218,...         1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frames1</th>\n",
       "      <th>frames2</th>\n",
       "      <th>is_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[193, 149, 148], [193, 149, 148], [195, 151,...</td>\n",
       "      <td>[[[57, 141, 56], [49, 133, 48], [61, 145, 60],...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[142, 137, 134], [145, 140, 137], [147, 142,...</td>\n",
       "      <td>[[[24, 22, 30], [24, 22, 30], [24, 22, 30], [2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[147, 155, 160], [147, 155, 160], [147, 155,...</td>\n",
       "      <td>[[[33, 37, 41], [33, 37, 41], [33, 37, 41], [3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[188, 194, 195], [188, 194, 195], [188, 194,...</td>\n",
       "      <td>[[[92, 11, 16], [92, 11, 16], [92, 11, 16], [9...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[155, 174, 184], [156, 175, 185], [156, 175,...</td>\n",
       "      <td>[[[217, 220, 227], [216, 219, 226], [215, 218,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": "train_df.fillna(value=0, inplace=True)\ny = train_df[\"is_match\"].values\nx = train_df[[\"frames1\", \"frames2\"]]\nprint(x.shape)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-15T14:26:41.184487Z",
     "iopub.execute_input": "2024-06-15T14:26:41.185363Z",
     "iopub.status.idle": "2024-06-15T14:26:41.194655Z",
     "shell.execute_reply.started": "2024-06-15T14:26:41.185329Z",
     "shell.execute_reply": "2024-06-15T14:26:41.193612Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-15T17:15:35.551882Z",
     "start_time": "2024-06-15T17:15:35.548497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3443, 2)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.python.keras.backend as K\n",
    "from keras.layers import Activation\n",
    "#from keras.layers import Input, Lambda, Dense, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, Input, Lambda\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8)\n",
    "\n",
    "'''def build_base_network():\n",
    "    \n",
    "    seq = Sequential()    \n",
    "    nb_filter = [6, 12]\n",
    "    kernel_size = 3    \n",
    "    \n",
    "    seq.add(Input(shape=(2, )))\n",
    "    #convolutional layer 1\n",
    "    seq.add(Convolution2D(nb_filter[0], kernel_size,\n",
    "                          padding='valid', data_format=\"channels_first\"))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "    seq.add(Dropout(.25))\n",
    "    \n",
    "    #convolutional layer 2\n",
    "    seq.add(Convolution2D(nb_filter[1], kernel_size, kernel_size, padding='valid', data_format=\"channels_first\"))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")) \n",
    "    seq.add(Dropout(.25))\n",
    "\n",
    "    #flatten \n",
    "    seq.add(Flatten())\n",
    "    seq.add(Dense(128, activation='relu'))\n",
    "    seq.add(Dropout(0.1))\n",
    "    seq.add(Dense(50, activation='relu'))\n",
    "    return seq'''\n",
    "\n",
    "\n",
    "def build_base_network(input_shape):\n",
    "    \n",
    "    seq = Sequential()    \n",
    "    nb_filter = [6, 12]\n",
    "    kernel_size = 3    \n",
    "    \n",
    "    # Convolutional layer 1\n",
    "    seq.add (Conv2D(nb_filter[0], (kernel_size, kernel_size), input_shape=input_shape,\n",
    "                   padding='valid'))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "    seq.add(Dropout(0.25))\n",
    "    \n",
    "    # Convolutional layer 2\n",
    "    seq.add(Conv2D(nb_filter[1], (kernel_size, kernel_size), padding='valid'))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "    seq.add(Dropout(0.25))\n",
    "\n",
    "    # Flatten\n",
    "    seq.add(Flatten())\n",
    "    seq.add(Dense(128, activation='relu'))\n",
    "    seq.add(Dropout(0.1))\n",
    "    seq.add(Dense(50, activation='relu'))\n",
    "    return seq\n",
    "\n",
    "input_dim = (400, 400, 3)\n",
    "input_a = Input(shape=input_dim)\n",
    "input_b = Input(shape=input_dim)\n",
    "#img_a = Input(shape=input_dim)\n",
    "#img_b = Input(shape=input_dim)\n",
    "\n",
    "base_network = build_base_network(input_dim)\n",
    "#feat_vecs_a = base_network(img_a)\n",
    "#feat_vecs_b = base_network(img_b)\n",
    "feat_vecs_a = base_network(input_a)\n",
    "feat_vecs_b = base_network(input_b)\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    euclidean_distance = K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "    #print(euclidean_distance)\n",
    "    return euclidean_distance\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "    \n",
    "\n",
    "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([feat_vecs_a, feat_vecs_b])\n",
    "\n",
    "\n",
    "epochs = 40\n",
    "rms = RMSprop()\n",
    "\n",
    "model = Model(inputs=[input_a, input_b], outputs=distance)\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "model.compile(loss=contrastive_loss, optimizer=rms)\n",
    "#x_train = x_train[0]\n",
    "print(x_train[\"frames1\"].head())\n",
    "img_1 = np.array(x_train[\"frames1\"].to_list(), dtype=np.float32)\n",
    "img_2 = np.array(x_train[\"frames2\"].to_list(), dtype=np.float32)\n",
    "img_1 = img_1 / 255.0\n",
    "img_2 = img_2 / 255.0\n",
    "#im = Image.fromarray(np.uint8(cm.gist_earth(myarray)*255))\n",
    "#np_img = np.squeeze(np.array(img_1)[0],0)\n",
    "#pil_img = Image.fromarray(np_img, 'RGB')\n",
    "\n",
    "\n",
    "\n",
    "model.fit([img_1, img_2], y_train, validation_split=.25, batch_size=128, verbose=2, epochs=epochs)\n",
    "\n",
    "img_1_test = np.array(x_test[\"frames1\"].to_list(), dtype=np.float32)\n",
    "img_2_test = np.array(x_test[\"frames2\"].to_list(), dtype=np.float32)\n",
    "img_1_test = img_1_test / 255.0\n",
    "img_2_test = img_2_test / 255.0\n",
    "\n",
    "pred = model.predict([img_1_test, img_2_test])\n",
    "\n",
    "print(pred.var()) #distance ?\n",
    "def compute_accuracy(predictions, labels):\n",
    "    return labels[predictions.ravel() < 0.5].mean()\n",
    "\n",
    "print(compute_accuracy(pred, y_test))\n",
    "\n",
    "\n",
    "model.save_weights('model.weights.h5')\n",
    "with open('model_architecture.json', 'w') as f:\n",
    "    f.write(model.to_json())\n",
    "print('saved')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-15T14:27:05.726681Z",
     "iopub.execute_input": "2024-06-15T14:27:05.727517Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-15T17:27:05.186186Z",
     "start_time": "2024-06-15T17:15:35.551882Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\PyCharm Community Edition 2021.1.1\\projects\\x5tech_halluc\\hall_venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1660    [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
      "1782    [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
      "1842    [[[72, 33, 21], [72, 33, 21], [72, 33, 21], [7...\n",
      "3266    [[[31, 118, 196], [31, 118, 196], [31, 118, 19...\n",
      "2693    [[[121, 124, 116], [123, 126, 118], [125, 128,...\n",
      "Name: frames1, dtype: object\n",
      "Epoch 1/40\n",
      "17/17 - 19s - 1s/step - loss: 153.2601 - val_loss: 0.4377\n",
      "Epoch 2/40\n",
      "17/17 - 17s - 995ms/step - loss: 0.4816 - val_loss: 0.3201\n",
      "Epoch 3/40\n",
      "17/17 - 17s - 976ms/step - loss: 0.4825 - val_loss: 2.5429\n",
      "Epoch 4/40\n",
      "17/17 - 17s - 975ms/step - loss: 1.7005 - val_loss: 0.3688\n",
      "Epoch 5/40\n",
      "17/17 - 16s - 958ms/step - loss: 0.5800 - val_loss: 0.5186\n",
      "Epoch 6/40\n",
      "17/17 - 17s - 977ms/step - loss: 1.0822 - val_loss: 0.5133\n",
      "Epoch 7/40\n",
      "17/17 - 17s - 984ms/step - loss: 0.4945 - val_loss: 0.5039\n",
      "Epoch 8/40\n",
      "17/17 - 16s - 971ms/step - loss: 1.3270 - val_loss: 0.5055\n",
      "Epoch 9/40\n",
      "17/17 - 17s - 1s/step - loss: 0.4837 - val_loss: 0.5004\n",
      "Epoch 10/40\n",
      "17/17 - 16s - 968ms/step - loss: 0.4769 - val_loss: 0.5026\n",
      "Epoch 11/40\n",
      "17/17 - 16s - 956ms/step - loss: 0.4737 - val_loss: 0.4940\n",
      "Epoch 12/40\n",
      "17/17 - 16s - 960ms/step - loss: 0.4850 - val_loss: 0.5043\n",
      "Epoch 13/40\n",
      "17/17 - 16s - 933ms/step - loss: 0.4663 - val_loss: 0.4207\n",
      "Epoch 14/40\n",
      "17/17 - 16s - 946ms/step - loss: 0.3492 - val_loss: 0.3862\n",
      "Epoch 15/40\n",
      "17/17 - 16s - 937ms/step - loss: 0.2840 - val_loss: 0.4280\n",
      "Epoch 16/40\n",
      "17/17 - 16s - 940ms/step - loss: 0.2522 - val_loss: 0.4128\n",
      "Epoch 17/40\n",
      "17/17 - 16s - 956ms/step - loss: 0.2208 - val_loss: 0.2847\n",
      "Epoch 18/40\n",
      "17/17 - 16s - 938ms/step - loss: 0.1903 - val_loss: 0.3087\n",
      "Epoch 19/40\n",
      "17/17 - 16s - 945ms/step - loss: 0.1759 - val_loss: 0.3300\n",
      "Epoch 20/40\n",
      "17/17 - 17s - 993ms/step - loss: 0.1621 - val_loss: 0.2915\n",
      "Epoch 21/40\n",
      "17/17 - 16s - 943ms/step - loss: 0.1335 - val_loss: 0.2736\n",
      "Epoch 22/40\n",
      "17/17 - 16s - 960ms/step - loss: 0.1111 - val_loss: 0.2771\n",
      "Epoch 23/40\n",
      "17/17 - 17s - 996ms/step - loss: 0.1068 - val_loss: 0.2224\n",
      "Epoch 24/40\n",
      "17/17 - 16s - 960ms/step - loss: 0.1059 - val_loss: 0.2543\n",
      "Epoch 25/40\n",
      "17/17 - 16s - 967ms/step - loss: 0.0751 - val_loss: 0.2671\n",
      "Epoch 26/40\n",
      "17/17 - 17s - 1s/step - loss: 0.0808 - val_loss: 0.2147\n",
      "Epoch 27/40\n",
      "17/17 - 17s - 973ms/step - loss: 0.0640 - val_loss: 0.1776\n",
      "Epoch 28/40\n",
      "17/17 - 17s - 1s/step - loss: 0.0634 - val_loss: 0.1928\n",
      "Epoch 29/40\n",
      "17/17 - 17s - 971ms/step - loss: 0.0614 - val_loss: 0.1816\n",
      "Epoch 30/40\n",
      "17/17 - 16s - 959ms/step - loss: 0.0526 - val_loss: 0.1883\n",
      "Epoch 31/40\n",
      "17/17 - 18s - 1s/step - loss: 0.0430 - val_loss: 0.1607\n",
      "Epoch 32/40\n",
      "17/17 - 17s - 999ms/step - loss: 0.0555 - val_loss: 0.2216\n",
      "Epoch 33/40\n",
      "17/17 - 16s - 970ms/step - loss: 0.0351 - val_loss: 0.1622\n",
      "Epoch 34/40\n",
      "17/17 - 16s - 935ms/step - loss: 0.0311 - val_loss: 0.1737\n",
      "Epoch 35/40\n",
      "17/17 - 16s - 953ms/step - loss: 0.0400 - val_loss: 0.1926\n",
      "Epoch 36/40\n",
      "17/17 - 16s - 950ms/step - loss: 0.0269 - val_loss: 0.2131\n",
      "Epoch 37/40\n",
      "17/17 - 17s - 984ms/step - loss: 0.0309 - val_loss: 0.1509\n",
      "Epoch 38/40\n",
      "17/17 - 17s - 974ms/step - loss: 0.0214 - val_loss: 0.1486\n",
      "Epoch 39/40\n",
      "17/17 - 16s - 940ms/step - loss: 0.0490 - val_loss: 0.1396\n",
      "Epoch 40/40\n",
      "17/17 - 16s - 934ms/step - loss: 0.0192 - val_loss: 0.1907\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 50ms/step\n",
      "0.2377676\n",
      "0.6633858267716536\n",
      "saved\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  }
 ]
}
