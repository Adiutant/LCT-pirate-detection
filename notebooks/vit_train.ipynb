{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:06:42.159426Z",
     "start_time": "2024-06-23T22:06:36.093388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install tf-keras\n",
    "!pip install accelerate -U"
   ],
   "id": "119178607b53404f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-keras in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (2.16.0)\n",
      "Requirement already satisfied: tensorflow<2.17,>=2.16 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tf-keras) (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: packaging in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (68.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.41.2)\n",
      "Requirement already satisfied: rich in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (0.31.0)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from accelerate) (2.3.1)\n",
      "Requirement already satisfied: huggingface-hub in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from accelerate) (0.23.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: sympy in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
      "Requirement already satisfied: networkx in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: fsspec in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: requests in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from huggingface-hub->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.4)\n",
      "Requirement already satisfied: intel-openmp==2021.* in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.13.0)\n",
      "Requirement already satisfied: colorama in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in e:\\pycharm community edition 2021.1.1\\projects\\lct\\lct-pirate-detection\\venv\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:52:09.337485Z",
     "start_time": "2024-06-23T22:52:09.318441Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"hello\")",
   "id": "20db6f007a004e10",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T23:00:38.787875Z",
     "start_time": "2024-06-23T22:58:11.856105Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118",
   "id": "6d780b03aaa6aae1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import ViTModel, ViTFeatureExtractor, TrainingArguments, Trainer\n",
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "import cv2"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:25:37.553409Z",
     "start_time": "2024-06-23T22:25:37.538411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, images, labels, feature_extractor):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.feature_extractor = feature_extractor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        image_1 = self.images[idx][0]\n",
    "        image_2 = self.images[idx][1]\n",
    "        label = self.labels[idx]\n",
    "        inputs_1 = self.feature_extractor(images=image_1, return_tensors=\"pt\")\n",
    "        inputs_2 = self.feature_extractor(images=image_2, return_tensors=\"pt\")\n",
    "        return {\n",
    "            \"pixel_values_1\": inputs_1[\"pixel_values\"].squeeze().to(device), \n",
    "            \"pixel_values_2\": inputs_2[\"pixel_values\"].squeeze().to(device),# Remove batch dimension\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long).to(device)\n",
    "        }"
   ],
   "id": "688d8f1bf0748494",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:25:37.569409Z",
     "start_time": "2024-06-23T22:25:37.554410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_frames(path, video_filename):\n",
    "    \n",
    "    # –ò—Å–ø–æ–ª—å–∑—É–µ–º OpenCV –¥–ª—è —á—Ç–µ–Ω–∏—è –≤–∏–¥–µ–æ\n",
    "    cap = cv2.VideoCapture(path + video_filename)\n",
    "\n",
    "    # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ö–æ–¥–Ω—É—é —á–∞—Å—Ç–æ—Ç—É –∫–∞–¥—Ä–æ–≤ –≤–∏–¥–µ–æ\n",
    "    original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    frames = []\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–∞–¥—Ä –∏–∑ BGR (OpenCV —Ñ–æ—Ä–º–∞—Ç) –≤ RGB\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –∫–∞–¥—Ä–∞ –¥–æ 224x224 (–∏–ª–∏ –¥—Ä—É–≥–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –ø–æ –≤–∞—à–µ–º—É –≤—ã–±–æ—Ä—É)\n",
    "\n",
    "        frame = cv2.resize(frame, (300, 300))\n",
    "    \n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–µ–∫—É—â–∏–π –∫–∞–¥—Ä\n",
    "        if frame_count % int(original_fps ) == 0:\n",
    "            frames.append(frame)  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä –∏ –º–µ–Ω—è–µ–º –ø–æ—Ä—è–¥–æ–∫ –æ—Å–µ–π\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    return np.stack(frames, axis=0)"
   ],
   "id": "b003f70ef372a9a6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:25:37.585410Z",
     "start_time": "2024-06-23T22:25:37.570411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_embedding_dataframe(video1_embeddings, video2_embeddings, interval1, interval2):\n",
    "    start1, end1 = map(int, interval1.split('-'))\n",
    "    start2, end2 = map(int, interval2.split('-'))\n",
    "\n",
    "    if (end1 - start1) != (end2 - start2):\n",
    "        raise ValueError(\"–ò–Ω—Ç–µ—Ä–≤–∞–ª—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π –¥–ª–∏–Ω—ã\")\n",
    "\n",
    "    frames1 = []\n",
    "    frames2 = []\n",
    "    is_match = []\n",
    "\n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–≤–ø–∞–¥–∞—é—â–∏–µ –ø–∞—Ä—ã –∏–∑ –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤\n",
    "    for i in range(end1 - start1):\n",
    "        emb1 = video1_embeddings[start1 + i]\n",
    "        emb2 = video2_embeddings[start2 + i]\n",
    "        \n",
    "        frames1.append(emb1)\n",
    "        frames2.append(emb2)\n",
    "        \n",
    "        is_match.append(1)\n",
    "\n",
    "    total_pairs = end1 - start1 + 1\n",
    "    all_indices_video1 = set(range(len(video1_embeddings)))\n",
    "    all_indices_video2 = set(range(len(video2_embeddings)))\n",
    "    interval_indices_video1 = set(range(start1, end1 + 1))\n",
    "    interval_indices_video2 = set(range(start2, end2 + 1))\n",
    "\n",
    "    non_interval_indices_video1 = list(all_indices_video1 - interval_indices_video1)\n",
    "    non_interval_indices_video2 = list(all_indices_video2 - interval_indices_video2)\n",
    "\n",
    "    if len(non_interval_indices_video1) < total_pairs or len(non_interval_indices_video2) < total_pairs:\n",
    "        raise ValueError(\"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤–Ω–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö –ø–∞—Ä\")\n",
    "\n",
    "    random_pairs_added = 0\n",
    "    while random_pairs_added < total_pairs:\n",
    "        idx1 = np.random.choice(non_interval_indices_video1)\n",
    "        idx2 = np.random.choice(non_interval_indices_video2)\n",
    "\n",
    "        emb1 = video1_embeddings[idx1]\n",
    "        emb2 = video2_embeddings[idx2]\n",
    "\n",
    "        frames1.append(emb1)\n",
    "        frames2.append(emb2)\n",
    "        \n",
    "        is_match.append(0)\n",
    "\n",
    "        random_pairs_added += 1\n",
    "\n",
    "    df_l = pd.DataFrame({\n",
    "        'frames1': frames1,\n",
    "        'frames2' : frames2,\n",
    "        'is_match': is_match\n",
    "    })\n",
    "\n",
    "    df_l = df_l.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    return df_l"
   ],
   "id": "d13eee5be57b17c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:27:29.447094Z",
     "start_time": "2024-06-23T22:25:38.989231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = pd.DataFrame()\n",
    "df = pd.read_csv(\"piracy_val.csv\")\n",
    "for _,row in df.iterrows():\n",
    "    piracy_ = extract_frames('val/', row[\"ID_piracy\"])\n",
    "    license_ = extract_frames('index/', row[\"ID_license\"])\n",
    "    proxy_df = create_embedding_dataframe(piracy_, license_, row[\"segment\"], row[\"segment.1\"])\n",
    "    train_df = pd.concat([train_df, proxy_df], ignore_index=True)\n",
    "\n",
    "train_df.head(5)"
   ],
   "id": "e66256ea4ecf6963",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                             frames1  \\\n",
       "0  [[[145, 166, 173], [147, 168, 175], [149, 170,...   \n",
       "1  [[[147, 155, 160], [147, 155, 160], [147, 155,...   \n",
       "2  [[[171, 162, 154], [169, 160, 152], [164, 155,...   \n",
       "3  [[[107, 143, 157], [106, 144, 157], [106, 144,...   \n",
       "4  [[[171, 179, 186], [172, 182, 188], [172, 184,...   \n",
       "\n",
       "                                             frames2  is_match  \n",
       "0  [[[28, 30, 30], [34, 36, 36], [39, 41, 41], [4...         0  \n",
       "1  [[[33, 37, 41], [33, 37, 41], [33, 37, 41], [3...         1  \n",
       "2  [[[91, 10, 17], [91, 10, 17], [92, 11, 18], [9...         1  \n",
       "3  [[[187, 49, 59], [185, 47, 57], [187, 46, 57],...         1  \n",
       "4  [[[67, 6, 11], [67, 6, 11], [67, 6, 11], [68, ...         1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frames1</th>\n",
       "      <th>frames2</th>\n",
       "      <th>is_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[145, 166, 173], [147, 168, 175], [149, 170,...</td>\n",
       "      <td>[[[28, 30, 30], [34, 36, 36], [39, 41, 41], [4...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[147, 155, 160], [147, 155, 160], [147, 155,...</td>\n",
       "      <td>[[[33, 37, 41], [33, 37, 41], [33, 37, 41], [3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[171, 162, 154], [169, 160, 152], [164, 155,...</td>\n",
       "      <td>[[[91, 10, 17], [91, 10, 17], [92, 11, 18], [9...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[107, 143, 157], [106, 144, 157], [106, 144,...</td>\n",
       "      <td>[[[187, 49, 59], [185, 47, 57], [187, 46, 57],...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[171, 179, 186], [172, 182, 188], [172, 184,...</td>\n",
       "      <td>[[[67, 6, 11], [67, 6, 11], [67, 6, 11], [68, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:27:29.463102Z",
     "start_time": "2024-06-23T22:27:29.449094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def combine_columns_to_numpy(df_l, col1, col2):\n",
    "    combined_list = []\n",
    "    for _, row_l in df_l.iterrows():\n",
    "        combined_array = np.stack((row_l[col1], row_l[col2]), axis=0)\n",
    "        combined_list.append(combined_array)\n",
    "    \n",
    "    return np.array(combined_list)"
   ],
   "id": "e2a1a0a7823069ff",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:27:31.620316Z",
     "start_time": "2024-06-23T22:27:29.464096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df.fillna(value=0, inplace=True)\n",
    "y = train_df[\"is_match\"].values\n",
    "x = train_df[[\"frames1\", \"frames2\"]]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8)\n",
    "images = np.array(combine_columns_to_numpy(x_train, \"frames1\", \"frames2\"), dtype=np.float32)\n"
   ],
   "id": "be34db5a87b24c9",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:27:31.636316Z",
     "start_time": "2024-06-23T22:27:31.623317Z"
    }
   },
   "cell_type": "code",
   "source": "print(images.shape)",
   "id": "14c6342c0f4ff725",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2754, 2, 300, 300, 3)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:27:31.870389Z",
     "start_time": "2024-06-23T22:27:31.637317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö\n",
    "num_samples = 1000\n",
    "num_classes = 2\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑—á–∏–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "dataset = CustomImageDataset(images, y_train, feature_extractor)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n"
   ],
   "id": "f640cfe0c2a49ead",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\PyCharm Community Edition 2021.1.1\\projects\\LCT\\LCT-pirate-detection\\venv\\lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:27:33.128885Z",
     "start_time": "2024-06-23T22:27:31.871389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "class ViTForImageClassification(torch.nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ViTForImageClassification, self).__init__()\n",
    "        self.vit = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "        self.classifier = torch.nn.Linear(self.vit.config.hidden_size * 2, num_classes)\n",
    "\n",
    "    def forward(self, pixel_values_1, pixel_values_2, labels=None):\n",
    "        outputs_1 = self.vit(pixel_values=pixel_values_1)\n",
    "        outputs_2 = self.vit(pixel_values=pixel_values_2)\n",
    "        \n",
    "        # Extract the embeddings of the CLS token from both outputs\n",
    "        cls_embedding_1 = outputs_1.last_hidden_state[:, 0, :]  # CLS token\n",
    "        cls_embedding_2 = outputs_2.last_hidden_state[:, 0, :]  # CLS token\n",
    "        \n",
    "        # Concatenate the embeddings\n",
    "        combined_embeddings = torch.cat((cls_embedding_1, cls_embedding_2), dim=1)\n",
    "        \n",
    "        # Pass the combined embeddings through the classifier\n",
    "        logits = self.classifier(combined_embeddings)\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "            return loss, logits\n",
    "        \n",
    "        return logits.detach().cpu().numpy()\n",
    "\n",
    "model = ViTForImageClassification()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# Define accuracy metric\n",
    "metric = load_metric(\"accuracy\", trust_remote_code=True)\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return metric.compute(predictions=preds, references=p.label_ids)\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ],
   "id": "8ffb5aa574d2de14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10728\\3707012446.py:45: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"accuracy\", trust_remote_code=True)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T22:27:51.806167Z",
     "start_time": "2024-06-23T22:27:33.129887Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()\n",
   "id": "4b79ab92d8713d52",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='519' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/519 : < :, Epoch 0.01/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\PyCharm Community Edition 2021.1.1\\projects\\LCT\\LCT-pirate-detection\\venv\\lib\\site-packages\\transformers\\trainer.py:1885\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   1883\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[0;32m   1884\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1885\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1886\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1887\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1888\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1889\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1890\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\PyCharm Community Edition 2021.1.1\\projects\\LCT\\LCT-pirate-detection\\venv\\lib\\site-packages\\transformers\\trainer.py:2216\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   2213\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_step_begin(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[0;32m   2215\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39maccumulate(model):\n\u001B[1;32m-> 2216\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2218\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   2219\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[0;32m   2220\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[0;32m   2221\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[0;32m   2222\u001B[0m ):\n\u001B[0;32m   2223\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[0;32m   2224\u001B[0m     tr_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[1;32mE:\\PyCharm Community Edition 2021.1.1\\projects\\LCT\\LCT-pirate-detection\\venv\\lib\\site-packages\\transformers\\trainer.py:3250\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[1;34m(***failed resolving arguments***)\u001B[0m\n\u001B[0;32m   3248\u001B[0m         scaled_loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m   3249\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 3250\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maccelerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3252\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\u001B[38;5;241m.\u001B[39mdetach() \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mgradient_accumulation_steps\n",
      "File \u001B[1;32mE:\\PyCharm Community Edition 2021.1.1\\projects\\LCT\\LCT-pirate-detection\\venv\\lib\\site-packages\\accelerate\\accelerator.py:2134\u001B[0m, in \u001B[0;36mAccelerator.backward\u001B[1;34m(self, loss, **kwargs)\u001B[0m\n\u001B[0;32m   2132\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlomo_backward(loss, learning_rate)\n\u001B[0;32m   2133\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2134\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mE:\\PyCharm Community Edition 2021.1.1\\projects\\LCT\\LCT-pirate-detection\\venv\\lib\\site-packages\\torch\\_tensor.py:525\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    517\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    518\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    523\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    524\u001B[0m     )\n\u001B[1;32m--> 525\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\PyCharm Community Edition 2021.1.1\\projects\\LCT\\LCT-pirate-detection\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:267\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    262\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    264\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    266\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 267\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    274\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    275\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\PyCharm Community Edition 2021.1.1\\projects\\LCT\\LCT-pirate-detection\\venv\\lib\\site-packages\\torch\\autograd\\graph.py:744\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    742\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    743\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 744\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    745\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    746\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    747\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    748\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "test_images = np.random.rand(200, 200, 200, 3).astype(np.float32)\n",
    "test_labels = np.random.randint(0, num_classes, 200)\n",
    "test_dataset = CustomImageDataset(test_images, test_labels, feature_extractor)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "trainer.evaluate(test_dataset=test_dataset)\n"
   ],
   "id": "38cb5a40db561dcd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
